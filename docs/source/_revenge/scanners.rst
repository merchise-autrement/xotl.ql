=======================================
 From byte-code to a query syntax tree
=======================================

.. role:: name

This document describes the core of `revenge` algorithm for getting a `query
synxtax tree <qst>`:ref: from the byte-code of generator expressions.  This
document spans several highly coupled modules:

- The `xotl.ql.revenge.scanners`:mod: module,
- the `xotl.ql.revenge.parsers`:mod: module,
- and (parts of) the `xotl.ql.revenge.qst`:mod: module.

Though we try to make a linear exposition of the matter from the scanner that
yields token to the parser for the recognizing the program and the query build
for final construction of the query syntax tree; the high degree of coupling
between those phases imposes to describe later actions upfront.

This package derives from the work of `John Aycock`:name: and others on the
`uncompyle2`_ package.  However, since the goal of that package is much more
ambitious we have stripped much of the original grammar and the scanner has
been almost entirely reimplemented.

`uncompyle2` handles the problem of getting Python source from the byte-code
(reverse engineering the byte-code) by casting as a parsing problem.  Thus
compiler techniques are applied.  The byte-code is passed to a `scanner` that
produce the tokens.  Then a `parser` recognizes if the stream of tokens can be
generated by a given grammar, if so, it produces a syntax tree that captures
the syntactical structure of the provide stream of tokens.  Finally a `walker`
transform the syntax tree into source code by traversing the syntax tree.

Module `xotl.ql.revenge.scanners`:mod:
======================================

.. module:: xotl.ql.revenge.scanners

This modules provides the `Scanner`:class: that gets the byte-code and
produces a stream of `Tokens <Token>`:class:.  Each token represents either an
actual byte-code instruction with is arguments, or a virtual instruction
provided solely for the purpose of making our `grammar
<xotl.ql.revenge.parsers>`:mod: easier to understand.

This document begins with an exploration of the byte-code for Python
expressions, and then describes the objects in the `scanners`:mod: module and
how the tokens are produced.


Byte-code tour
--------------

Let's inspect how simple expressions are compiled in different versions of
Python.

Basic expressions
~~~~~~~~~~~~~~~~~

Let's call basic expressions to those composed only by literals, variables
(attributes, subscript), function calls, and binary and unary operator,
excluding `conditional and boolean expressions`_ -- which we'll discuss later;
generator expressions and lambdas.

Yield expressions are also out the question cause they can only occur within
the body of a non-lambda function (i.e, not an expression).

These are all valid basic expressions (along with the produced byte-code in
Python 2.7 and Pypy 2.7):

- ``a``::

    >>> dis.dis(compile('a', '', 'eval'))
      1           0 LOAD_NAME                0 (a)
                  3 RETURN_VALUE

- ``a + 1``::

    >>> dis.dis(compile('a + 1', '', 'eval'))
      1           0 LOAD_NAME                0 (a)
                  3 LOAD_CONST               0 (1)
                  6 BINARY_ADD
                  7 RETURN_VALUE


- ``a(b[c**e/2:d], *y, **kw).at``::

    >>> dis.dis(compile('a(b[c**e/2:d], *y, **kw).at', '', 'eval'))
      1           0 LOAD_NAME                0 (a)
                  3 LOAD_NAME                1 (b)
                  6 LOAD_NAME                2 (c)
                  9 LOAD_NAME                3 (e)
                 12 BINARY_POWER
                 13 LOAD_CONST               0 (2)
                 16 BINARY_TRUE_DIVIDE
                 17 LOAD_NAME                4 (d)
                 20 SLICE+3
                 21 LOAD_NAME                5 (y)
                 24 LOAD_NAME                6 (kw)
                 27 CALL_FUNCTION_VAR_KW     1
                 30 LOAD_ATTR                7 (at)
                 33 RETURN_VALUE

The thing with basic expressions is they don't have any kind of JUMP in the
generated byte-code.  The byte-code for basic expression resembles the postfix
notation, where operands come before the operator.


Conditional and boolean expressions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Conditional and boolean expressions, on the other hand, do produce jumps in
the byte-code.  The don't run linearly from top to bottom.

Let's inspect some.

- ``a if x else y``

  In Python 2.7 and 3.4 this is compiled to::

    1           0 LOAD_NAME                0 (b)
                3 POP_JUMP_IF_FALSE       10
                6 LOAD_NAME                1 (a)
                9 RETURN_VALUE
          >>   10 LOAD_NAME                2 (c)
               13 RETURN_VALUE


  In Pypy 2.7.3::

    1           0 LOAD_NAME                0 (b)
                3 POP_JUMP_IF_FALSE       12
                6 LOAD_NAME                1 (a)
                9 JUMP_FORWARD             3 (to 15)
          >>   12 LOAD_NAME                2 (c)
          >>   15 RETURN_VALUE

  The difference is the 9th offset.

  It's easy to see we can do a transformation step for Pypy byte-code so that
  the final byte-code is the same as that of CPython:

    If the target of a ``JUMP_FORWARD`` (or ``JUMP_ABSOLUTE``) is a
    ``RETURN_VALUE`` replace the JUMP with a ``RETURN_VALUE``.

  Notice, however, this affect the offsets since JUMP_FORWARD has an argument
  and RETURN_VALUE does not.  Then to keep things simple we can modify the
  rule to be:

    If the target of a ``JUMP_FORWARD`` (or ``JUMP_ABSOLUTE``) is a
    ``RETURN_VALUE`` replace the JUMP with the following instructions::

      RETURN_VALUE
      NOP
      NOP

  Notice we don't really care about optimization just normalization of the
  generated byte-code.  But since the grammar would be complicated with
  ``NOPs`` we must remove them afterwards.

  The algorithm for removing ``NOPs`` may be ported from the
  ``Python/peephole.c``.

  .. seealso:: The functions `without_nops`:func: and
               `normalize_pypy_conditional`:func:.



- ``x and a or y``.

  In Python 2.7 and 3.4 it looks like::

    >>> dis.dis(compile('x and a or y', '', 'eval'))
      1           0 LOAD_NAME                0 (x)
                  3 POP_JUMP_IF_FALSE       12
                  6 LOAD_NAME                1 (a)
                  9 JUMP_IF_TRUE_OR_POP     15
            >>   12 LOAD_NAME                2 (y)
            >>   15 RETURN_VALUE

  In Pypy 2.7.3::

    >>> dis.dis(compile('x and a or y', '', 'eval'))
      1           0 LOAD_NAME                0 (x)
                  3 JUMP_IF_FALSE_OR_POP     9
                  6 LOAD_NAME                1 (a)
            >>    9 JUMP_IF_TRUE_OR_POP     15
                 12 LOAD_NAME                2 (y)
            >>   15 RETURN_VALUE



``EXTENDED_ARG`` removal
~~~~~~~~~~~~~~~~~~~~~~~~

The ``EXTENDED_ARG`` opcode only comes when arguments in the next opcode are
two big to fit into 2 bytes.

The `Bytecode`:class: knows how to deal with extended arguments and the
produced `Instruction`:class: set have the arguments fully computed.  The
instruction set keeps the ``EXTENDED_ARG`` but we can easily skip it and never
produce a token for it.


List comprehensions in Pypy
~~~~~~~~~~~~~~~~~~~~~~~~~~~

In Pypy there's a ``BUILD_LIST_FROM_ARG`` opcode to speed list comprehensions
up.  This is basically an *informed* ``BUILD_LIST``: it peeks the TOS and
tries to guess the length of the list it will build, if it can't it will
behave as a ``BUILD_LIST 0``.

A list comprehension "``[a for a in b]``" will look like::

  1           0 LOAD_NAME                0 (b)
              3 BUILD_LIST_FROM_ARG      0
              6 GET_ITER
        >>    7 FOR_ITER                12 (to 22)
             10 STORE_NAME               1 (a)
             13 LOAD_NAME                1 (a)
             16 LIST_APPEND              2
             19 JUMP_ABSOLUTE            7
        >>   22 RETURN_VALUE

while in Python 2.7 the same comprehension yields::

  1           0 BUILD_LIST               0
              3 LOAD_NAME                0 (b)
              6 GET_ITER
        >>    7 FOR_ITER                12 (to 22)
             10 STORE_NAME               1 (a)
             13 LOAD_NAME                1 (a)
             16 LIST_APPEND              2
             19 JUMP_ABSOLUTE            7
        >>   22 RETURN_VALUE


Notice that the only change is that Pypy don't use the ``BUILD_LIST 0`` but
add a ``BUILD_LIST_FROM_ARG`` **after** loading the list.

We can't simply swap the codes in this case, their order is also affected.

We think this issue should be addressed by the parser and not the scanner
since the iterable can be any expression, i.e. not a single ``LOAD_NAME``.


Virtual codes
~~~~~~~~~~~~~

Most of the time the scanner will produce tokens that wrap byte-code
instructions.  But for byte-codes that take arguments which *indicate how many
items to take from the stack* (BUILD_LIST, BUILD_TUPLE, BUILD_SLICE, etc) the
scanner transforms them in *customized* versions depending on the argument.

For instance the instruction ``BUILD_LIST 3`` yields a token
``<BUILD_LIST_3>`` [#token-repr]_.  The scanner actually returns the stream of
tokens a map from *customized* code names to arguments.  This means that a
*customized* code must be produced per argument value found in the original
instruction set.

The program shown below produces two customized tokens ``<BUILD_LIST_3>`` and
``<BUILD_LIST_2>``::

  >>> dis.dis(compile('[1, 2, 3] + [9, 0]', '', 'eval'))
    1           0 LOAD_CONST               0 (1)
                3 LOAD_CONST               1 (2)
                6 LOAD_CONST               2 (3)
                9 BUILD_LIST               3
               12 LOAD_CONST               3 (9)
               15 LOAD_CONST               4 (0)
               18 BUILD_LIST               2
               21 BINARY_ADD
               22 RETURN_VALUE

Before the parser begins to recognize the program it should build new rules
from those customized tokens.  For instance for recognizing a
``<BUILD_LIST_3>`` it could add the rule::

  list_expression ::= expr expr expr BUILD_LIST_3


.. seealso:: The `~xotl.ql.revenge.parsers`:mod: module.


.. [#token-repr] In this document we use angular brackets to distinguish
   tokens from byte-code instructions names.


JUMP_BACK
+++++++++

A ``JUMP_ABSOLUTE`` that targets a previous instruction yields a virtual code
``JUMP_BACK``.

This allows the parser to recognize loops inside comprehensions more easily.
The ``JUMP_ABSOLUTE`` in a comprehension always jumps to the ``FOR_ITER`` to
get the next item.


API of the module
-----------------

.. autofunction:: without_nops

.. autofunction:: normalize_pypy_conditional

.. autoclass:: Token


.. _uncompyle2: https://github.com/mvaled/uncompyle2
